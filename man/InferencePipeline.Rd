% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/template_pipeline_inference.R
\name{InferencePipeline}
\alias{InferencePipeline}
\title{InferencePipeline for Sagemaker}
\description{
Creates a standard inference pipeline with the following steps in order:
\itemize{
  \item{Train preprocessor}
  \item{Create preprocessor model}
  \item{Transform input data using preprocessor model}
  \item{Train estimator}
  \item{Create estimator model}
  \item{Endpoint configuration}
  \item{Deploy estimator model}
}
}
\section{Super class}{
\code{\link[stepfunctions:WorkflowTemplate]{stepfunctions::WorkflowTemplate}} -> \code{InferencePipeline}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{InferencePipeline$new()}}
\item \href{#method-build_workflow_definition}{\code{InferencePipeline$build_workflow_definition()}}
\item \href{#method-execute}{\code{InferencePipeline$execute()}}
\item \href{#method-clone}{\code{InferencePipeline$clone()}}
}
}
\if{html}{
\out{<details open ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="stepfunctions" data-topic="WorkflowTemplate" data-id="create">}\href{../../stepfunctions/html/WorkflowTemplate.html#method-create}{\code{stepfunctions::WorkflowTemplate$create()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="stepfunctions" data-topic="WorkflowTemplate" data-id="format">}\href{../../stepfunctions/html/WorkflowTemplate.html#method-format}{\code{stepfunctions::WorkflowTemplate$format()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="stepfunctions" data-topic="WorkflowTemplate" data-id="get_workflow">}\href{../../stepfunctions/html/WorkflowTemplate.html#method-get_workflow}{\code{stepfunctions::WorkflowTemplate$get_workflow()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="stepfunctions" data-topic="WorkflowTemplate" data-id="render_graph">}\href{../../stepfunctions/html/WorkflowTemplate.html#method-render_graph}{\code{stepfunctions::WorkflowTemplate$render_graph()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Initialize InferencePipeline class
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{InferencePipeline$new(
  preprocessor,
  estimator,
  inputs,
  s3_bucket,
  role,
  client = NULL,
  compression_type = NULL,
  content_type = NULL,
  pipeline_name = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{preprocessor}}{(sagemaker.estimator.EstimatorBase): The estimator use
to preprocess and transform the training data.}

\item{\code{estimator}}{(sagemaker.estimator.EstimatorBase): The estimator to use
for training. Can be a BYO estimator, Framework estimator or Amazon
algorithm estimator.}

\item{\code{inputs}}{: Information about the training data. Please refer to the `fit()`
             method of the associated estimator, as this can take any of the following forms:
\itemize{
    \item{(str) - The S3 location where training data is saved.}
    \item{(list[str, str] or list[str, `sagemaker.inputs.TrainingInput`]) - If
          using multiple channels for training data, you can specify a list mapping
          channel names to strings or `sagemaker.inputs.TrainingInput` objects.}
    \item{(`sagemaker.inputs.TrainingInput`) - Channel configuration for S3 data
          sources that can provide additional information about the training dataset.
         See `sagemaker.inputs.TrainingInput` for full details.}
    \item{(`sagemaker.amazon.amazon_estimator.RecordSet`) - A collection of Amazon
         `Record` objects serialized and stored in S3. For use with an estimator
         for an Amazon algorithm.}
    \item{(list[`sagemaker.amazon.amazon_estimator.RecordSet`]) - A list of
         `sagemaker.amazon.amazon_estimator.RecordSet` objects, where each instance
         is a different channel of training data.}
}}

\item{\code{s3_bucket}}{(str): S3 bucket under which the output artifacts from
the training job will be stored. The parent path used is built
using the format: ``s3://{s3_bucket}/{pipeline_name}/models/{job_name}/``.
In this format, `pipeline_name` refers to the keyword argument provided
for TrainingPipeline. If a `pipeline_name` argument was not provided,
one is auto-generated by the pipeline as `training-pipeline-<timestamp>`.
Also, in the format, `job_name` refers to the job name provided
when calling the :meth:`TrainingPipeline.run()` method.}

\item{\code{role}}{(str): An AWS IAM role (either name or full Amazon Resource Name (ARN)).
This role is used to create, manage, and execute the Step Functions workflows.}

\item{\code{client}}{(SFN.Client, optional): \code{\link[paws]{sfn}} client to use for creating and
interacting with the training pipeline in Step Functions. (default: None)}

\item{\code{compression_type}}{(str, optional): Compression type (Gzip/None) of the
file for TransformJob. (default:None)}

\item{\code{content_type}}{(str, optional): Content type (MIME) of the document to
be used in preprocessing script. See SageMaker documentation for
more details. (default:None)}

\item{\code{pipeline_name}}{(str, optional): Name of the pipeline. This name will
be used to name jobs (if not provided when calling execute()),
models, endpoints, and S3 objects created by the pipeline. If a
`pipeline_name` argument was not provided, one is auto-generated
by the pipeline as `training-pipeline-<timestamp>`. (default:None)}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-build_workflow_definition"></a>}}
\if{latex}{\out{\hypertarget{method-build_workflow_definition}{}}}
\subsection{Method \code{build_workflow_definition()}}{
Build the workflow definition for the inference pipeline with
             all the states involved.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{InferencePipeline$build_workflow_definition()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
:class:`~stepfunctions.steps.states.Chain`: Workflow definition as
             a chain of states involved in the the inference pipeline.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-execute"></a>}}
\if{latex}{\out{\hypertarget{method-execute}{}}}
\subsection{Method \code{execute()}}{
Run the inference pipeline.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{InferencePipeline$execute(job_name = NULL, hyperparameters = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{job_name}}{(str, optional): Name for the training job. This is also
used as suffix for the preprocessing job as `preprocess-<job_name>`.
If one is not provided, a job name will be auto-generated. (default: None)}

\item{\code{hyperparameters}}{(list, optional): Hyperparameters for the estimator
training. (default: None)}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
:R:class:`~stepfunctions.workflow.Execution`: Running instance of the inference pipeline.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{InferencePipeline$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
